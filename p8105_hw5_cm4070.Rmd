---
title: "p8105_hw5_cm4070.git"
output: github_document
---

```{r setup}
library(tidyverse)
library(readr)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1

This code will import and clean the homicides data.

```{r}
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

data_homicides = read_csv(url(urlfile), na = c("", "Unknown")) %>% 
  mutate(city_state = str_c(city, state),
  resolution = case_when(
    disposition == "Closed without arrest" ~ "unsolved", 
    disposition == "Open/No arrest" ~ "unsolved",
    disposition == "Closed by arrest" ~ "solved"
  )) %>%
  relocate(city_state) %>%
  filter(city_state != "TulsaAL")
```

This dataset contains `r nrow(data_homicides)` rows and `r ncol(data_homicides)` columns, with each row representing a criminal homicide over the past decade in 50 of the largest American cities. Variables include the location of the killing, whether an arrest was made and basic demographic information about each victim.

Focus on Baltimore, MD. Find proportion of homicides that are unsolved.

```{r}
baltimore_df = 
  data_homicides %>%
  filter(city_state == "BaltimoreMD")

baltimore_summary = 
  baltimore_df %>%
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test =
  prop.test(x = baltimore_summary  %>% pull(unsolved), 
          n = baltimore_summary %>% pull(n))

baltimore_test %>%
  broom::tidy()
```

Let's try to iterate across cities!

First off, write a function and test the function on a few sample cities.

```{r}
prop_test_function = function(city_df) {
  
  city_summary = 
    city_df %>%
    summarize(
     unsolved = sum(resolution == "unsolved"),
     n = n()
  )

  city_test =
  prop.test(
          x = city_summary  %>% pull(unsolved), 
          n = city_summary %>% pull(n))
  
  return(city_test)
  
}

prop_test_function(baltimore_df)

data_homicides %>%
  filter(city_state == "AlbuquerqueNM") %>%
  prop_test_function()
```

Now, let's iterate across all cities.

```{r}
results_df = 
  data_homicides %>%
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  )  %>%
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, starts_with("conf"))
```

Now, lets create a plot that shows the estimates and CI's for each city.

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

This code will create a dataframe with all file names, iterate over file names and read in data for each subject and save this as a new variable "participants", and then tidy data for spaghetti plot.

```{r, message = FALSE, warning = FALSE}
data_df = tibble(files = list.files("./data")) %>%
  mutate(files = str_c("data", files, sep = "/")) 

new_df = data_df %>%
  mutate(participants = map(files, read_csv)) %>%
  unnest() %>%
  mutate(subject_id = 1:20) %>%
  mutate(arm = case_when(str_detect(files, 'data/c') ~ "control", 
                         str_detect(files, 'data/e') ~ "experimental")) %>%
  select(-files) %>%
  pivot_longer(cols = week_1:week_8, names_to = "week", values_to = "observations")
```

This code creates a spaghetti plot which looks at the observations on each subject over time.

```{r}
spaghetti_plot = 
  ggplot(data = new_df, aes(x = week, y = observations, color = arm, group = subject_id)) + geom_line() +  geom_point() + geom_path() + labs(caption = "Observations on each subject over time")

spaghetti_plot
```

The plot shows that the experimental group appears to have consistently increasing number of observations over time. Every individual had an increased number of observation by week 8 than week 1. While the control group did not have a consistent trend over time. The number of observations within the control group varied, and by week 8 was approximately the same number of observations as week 1. 

## Problem 3

The code below uploads the `iris` dataset and introduces some missing values.

```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) 
```

The code below writes a function that fills in missing values, returns resulting vector, and confirms no remaining missing values.

```{r}
fill_in_missing = function(vector) {
  
  if (is.numeric(vector)) {
   vector = ifelse(is.na(vector), mean(vector, na.rm = TRUE),vector)
  }
  
  if (is.character(vector)) {
    vector = ifelse(is.na(vector),'virginica',vector)
    
  }
  
  return(vector)
}

output = map(iris_with_missing, fill_in_missing)

sum(is.na(output))
```



